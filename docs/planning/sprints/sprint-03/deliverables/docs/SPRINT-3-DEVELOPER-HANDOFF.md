# Sprint 3 Implementation - Developer Handoff

**Date:** 2025-11-19
**Sprint:** Sprint 3 - Workflow Engine & Core Services
**Scope:** 60 hours / ~60 files
**Status:** üü° Foundation Complete - Implementation In Progress

---

## Executive Summary

Sprint 3 adds workflow automation, document generation, file management, email services, and background job processing to InTime v3. This handoff document provides complete implementation details for all remaining work.

### Completed (20%)
- ‚úÖ Database migration files created (010-015)
- ‚úÖ NPM packages installed (puppeteer, handlebars, resend, docx)
- ‚úÖ Type definitions created (workflows/types.ts)
- ‚úÖ Migration application script created
- ‚úÖ Implementation roadmap documented

### Remaining (80%)
- ‚è≥ Apply migrations to database (MANUAL - see below)
- ‚è≥ Implement 5 core services (40 hours)
- ‚è≥ Create 5 tRPC routers (12 hours)
- ‚è≥ Build 2 admin dashboards (8 hours)
- ‚è≥ Write comprehensive tests (8 hours)

---

## CRITICAL: Apply Migrations First

**Before implementing services, apply migrations 010-015 via Supabase SQL Editor:**

### Step-by-Step Migration Instructions

1. **Open Supabase Dashboard**
   - Navigate to: https://supabase.com/dashboard/project/gkwhxmvugnjwwwiufmdy
   - Go to: SQL Editor

2. **Apply Migrations in Order** (MUST be in this exact order)

   **Migration 010: Workflow Engine**
   ```bash
   # Copy content of: src/lib/db/migrations/010_create_workflow_engine.sql
   # Paste into SQL Editor
   # Click "Run"
   # Verify: 5 tables, 4 functions, 2 views created
   ```

   **Migration 011: Document Service**
   ```bash
   # Copy content of: src/lib/db/migrations/011_create_document_service.sql
   # Paste into SQL Editor
   # Click "Run"
   # Verify: 2 tables, 2 seed templates created
   ```

   **Migration 012: File Management**
   ```bash
   # Copy content of: src/lib/db/migrations/012_create_file_management.sql
   # Paste into SQL Editor
   # Click "Run"
   # Verify: 1 table created
   ```

   **Migration 013: Email Service**
   ```bash
   # Copy content of: src/lib/db/migrations/013_create_email_service.sql
   # Paste into SQL Editor
   # Click "Run"
   # Verify: 2 tables, 4 seed email templates created
   ```

   **Migration 014: Background Jobs**
   ```bash
   # Copy content of: src/lib/db/migrations/014_create_background_jobs.sql
   # Paste into SQL Editor
   # Click "Run"
   # Verify: 1 table, 4 functions created
   ```

   **Migration 015: Seed Workflows**
   ```bash
   # Copy content of: src/lib/db/migrations/015_seed_workflows.sql
   # Paste into SQL Editor
   # Click "Run"
   # Verify: 3 workflows, 20 states, 19 transitions created
   ```

3. **Verify All Migrations Applied**
   ```sql
   -- Run this query to verify all tables exist
   SELECT tablename
   FROM pg_tables
   WHERE schemaname = 'public'
     AND tablename IN (
       'workflows', 'workflow_states', 'workflow_transitions',
       'workflow_instances', 'workflow_history',
       'document_templates', 'generated_documents',
       'file_uploads',
       'email_templates', 'email_logs',
       'background_jobs'
     )
   ORDER BY tablename;

   -- Expected: 11 rows

   -- Verify seed data
   SELECT name FROM workflows ORDER BY name;
   -- Expected: Candidate Placement, Job Requisition, Student Lifecycle

   SELECT name FROM document_templates ORDER BY name;
   -- Expected: Course Completion Certificate, Job Offer Letter

   SELECT name FROM email_templates ORDER BY name;
   -- Expected: Course Completion Certificate, Interview Scheduled, Password Reset, Welcome Email
   ```

---

## Phase 1: Core Services Implementation (40 hours)

### 1. WorkflowEngine Service (8 hours)

**File:** `src/lib/workflows/WorkflowEngine.ts`

```typescript
import { createClient } from '@/lib/supabase/server';
import type {
  StartWorkflowParams,
  TransitionParams,
  AvailableAction,
  WorkflowInstance,
  WorkflowHistoryEntry,
} from './types';

/**
 * WorkflowEngine - State machine implementation for business processes
 *
 * Provides methods to:
 * - Start workflow instances
 * - Transition between states
 * - Get available actions (with permission checks)
 * - Cancel workflows
 * - Query workflow history
 *
 * @example
 * ```typescript
 * const engine = new WorkflowEngine();
 *
 * // Start student lifecycle workflow
 * const instanceId = await engine.startWorkflow({
 *   workflowId: 'student-lifecycle-id',
 *   entityType: 'student',
 *   entityId: 'student-123',
 *   userId: 'user-456',
 *   orgId: 'org-789',
 * });
 *
 * // Transition to next state
 * await engine.transition({
 *   instanceId,
 *   action: 'schedule_assessment',
 *   userId: 'user-456',
 *   notes: 'Assessment scheduled for Jan 20',
 * });
 * ```
 */
export class WorkflowEngine {
  /**
   * Start a new workflow instance
   */
  async startWorkflow(params: StartWorkflowParams): Promise<string> {
    const supabase = await createClient();

    const { data, error } = await supabase.rpc('start_workflow', {
      p_workflow_id: params.workflowId,
      p_entity_type: params.entityType,
      p_entity_id: params.entityId,
      p_user_id: params.userId,
      p_org_id: params.orgId,
    });

    if (error) {
      throw new Error(`Failed to start workflow: ${error.message}`);
    }

    return data as string;
  }

  /**
   * Transition workflow instance to new state
   */
  async transition(params: TransitionParams): Promise<void> {
    const supabase = await createClient();

    const { error } = await supabase.rpc('transition_workflow', {
      p_instance_id: params.instanceId,
      p_action: params.action,
      p_user_id: params.userId,
      p_notes: params.notes || null,
      p_expected_version: params.expectedVersion || null,
    });

    if (error) {
      throw new Error(`Failed to transition workflow: ${error.message}`);
    }
  }

  /**
   * Get available actions for workflow instance
   */
  async getAvailableActions(
    instanceId: string,
    userId: string
  ): Promise<AvailableAction[]> {
    const supabase = await createClient();

    const { data, error } = await supabase.rpc('get_available_actions', {
      p_instance_id: instanceId,
      p_user_id: userId,
    });

    if (error) {
      throw new Error(`Failed to get available actions: ${error.message}`);
    }

    return data as AvailableAction[];
  }

  /**
   * Get workflow instance details
   */
  async getInstance(instanceId: string): Promise<WorkflowInstance | null> {
    const supabase = await createClient();

    const { data, error } = await supabase
      .from('workflow_instances')
      .select('*')
      .eq('id', instanceId)
      .single();

    if (error && error.code !== 'PGRST116') {
      throw new Error(`Failed to get workflow instance: ${error.message}`);
    }

    return data;
  }

  /**
   * Get workflow instance history (audit trail)
   */
  async getHistory(instanceId: string): Promise<WorkflowHistoryEntry[]> {
    const supabase = await createClient();

    const { data, error } = await supabase
      .from('workflow_history')
      .select(`
        *,
        from_state:workflow_states!from_state_id(name, display_name),
        to_state:workflow_states!to_state_id(name, display_name),
        performed_by_user:user_profiles!performed_by(full_name, email)
      `)
      .eq('workflow_instance_id', instanceId)
      .order('created_at', { ascending: true });

    if (error) {
      throw new Error(`Failed to get workflow history: ${error.message}`);
    }

    return data as any;
  }

  /**
   * Cancel an active workflow instance
   */
  async cancel(
    instanceId: string,
    userId: string,
    reason: string
  ): Promise<void> {
    const supabase = await createClient();

    const { error } = await supabase.rpc('cancel_workflow', {
      p_instance_id: instanceId,
      p_user_id: userId,
      p_reason: reason,
    });

    if (error) {
      throw new Error(`Failed to cancel workflow: ${error.message}`);
    }
  }

  /**
   * List workflow instances with filters
   */
  async listInstances(filters: {
    workflowId?: string;
    entityType?: string;
    status?: 'active' | 'completed' | 'cancelled' | 'failed';
    limit?: number;
    offset?: number;
  }) {
    const supabase = await createClient();

    let query = supabase.from('v_workflow_instances_with_state').select('*', {
      count: 'exact',
    });

    if (filters.workflowId) {
      query = query.eq('workflow_id', filters.workflowId);
    }

    if (filters.entityType) {
      query = query.eq('entity_type', filters.entityType);
    }

    if (filters.status) {
      query = query.eq('status', filters.status);
    }

    query = query
      .order('created_at', { ascending: false })
      .range(
        filters.offset || 0,
        (filters.offset || 0) + (filters.limit || 50) - 1
      );

    const { data, error, count } = await query;

    if (error) {
      throw new Error(`Failed to list workflow instances: ${error.message}`);
    }

    return { data, count: count || 0 };
  }

  /**
   * Get workflow metrics
   */
  async getMetrics() {
    const supabase = await createClient();

    const { data, error } = await supabase
      .from('v_workflow_metrics')
      .select('*');

    if (error) {
      throw new Error(`Failed to get workflow metrics: ${error.message}`);
    }

    return data;
  }
}

// Singleton instance
export const workflowEngine = new WorkflowEngine();
```

**Tests:** `src/lib/workflows/__tests__/WorkflowEngine.test.ts`

```typescript
import { describe, it, expect, beforeEach } from 'vitest';
import { WorkflowEngine } from '../WorkflowEngine';
import { createMockSupabaseClient } from '@/lib/testing/supabase-mock';

describe('WorkflowEngine', () => {
  let engine: WorkflowEngine;

  beforeEach(() => {
    engine = new WorkflowEngine();
  });

  it('should start a workflow instance', async () => {
    // Test implementation
  });

  it('should transition workflow to next state', async () => {
    // Test implementation
  });

  it('should get available actions with permission check', async () => {
    // Test implementation
  });

  it('should prevent invalid transitions', async () => {
    // Test implementation
  });

  it('should handle optimistic locking conflicts', async () => {
    // Test implementation
  });

  it('should cancel active workflow', async () => {
    // Test implementation
  });
});
```

---

### 2. DocumentService (8 hours)

**File:** `src/lib/documents/DocumentService.ts`

**Key Features:**
- PDF generation using Puppeteer
- DOCX generation using docx library
- Template rendering with Handlebars
- Supabase Storage integration
- Variable validation

**Implementation Pattern:**
```typescript
export class DocumentService {
  async generatePDF(
    templateId: string,
    variables: Record<string, any>,
    userId: string
  ): Promise<GeneratedDocument> {
    // 1. Fetch template
    // 2. Validate variables
    // 3. Render HTML with Handlebars
    // 4. Convert to PDF with Puppeteer
    // 5. Upload to Supabase Storage (documents bucket)
    // 6. Create metadata record in generated_documents table
    // 7. Publish document.generated event
  }

  async generateDOCX(
    templateId: string,
    variables: Record<string, any>,
    userId: string
  ): Promise<GeneratedDocument> {
    // Similar to PDF but using docx library
  }
}
```

**Environment Variables Required:**
```env
NEXT_PUBLIC_SUPABASE_URL=https://gkwhxmvugnjwwwiufmdy.supabase.co
NEXT_PUBLIC_SUPABASE_STORAGE_URL=https://gkwhxmvugnjwwwiufmdy.supabase.co/storage/v1
```

---

### 3. FileUploadService (6 hours)

**File:** `src/lib/files/FileUploadService.ts`

**Key Features:**
- Presigned URL generation for client-direct uploads
- Upload confirmation
- File metadata tracking
- RLS-enforced access control

**Implementation:**
```typescript
export class FileUploadService {
  async getUploadUrl(params: {
    bucket: string;
    fileName: string;
    contentType: string;
    entityType: string;
    entityId: string;
  }): Promise<{ uploadUrl: string; filePath: string }> {
    // 1. Validate bucket name
    // 2. Generate unique file path: {orgId}/{entityType}/{entityId}/{uuid}-{fileName}
    // 3. Create presigned URL with Supabase Storage
    // 4. Return URL and path
  }

  async confirmUpload(params: {
    fileId: string;
    filePath: string;
    bucket: string;
    fileName: string;
    fileSize: number;
    mimeType: string;
    entityType: string;
    entityId: string;
  }): Promise<FileUpload> {
    // 1. Verify file exists in storage
    // 2. Create metadata record in file_uploads table
    // 3. Publish file.uploaded event
  }
}
```

---

### 4. EmailService (6 hours)

**File:** `src/lib/emails/EmailService.ts`

**Key Features:**
- Resend API integration
- Template rendering with Handlebars
- Email logging for compliance
- Rate limiting (100/hour per user)
- Webhook handler for delivery status

**Implementation:**
```typescript
import { Resend } from 'resend';

export class EmailService {
  private resend: Resend;

  constructor() {
    if (!process.env.RESEND_API_KEY) {
      throw new Error('RESEND_API_KEY not configured');
    }
    this.resend = new Resend(process.env.RESEND_API_KEY);
  }

  async sendEmail(params: {
    templateId: string;
    to: string;
    variables: Record<string, any>;
    userId: string;
  }): Promise<{ emailLogId: string; resendId: string }> {
    // 1. Fetch template
    // 2. Render subject and body with Handlebars
    // 3. Send via Resend API
    // 4. Create log entry in email_logs
    // 5. Publish email.sent event
  }
}
```

**Webhook Handler:** `src/app/api/webhooks/resend/route.ts`
```typescript
export async function POST(request: Request) {
  // Handle Resend webhook events:
  // - email.delivered
  // - email.bounced
  // - email.opened
  // - email.clicked
  // Update email_logs table accordingly
}
```

**Environment Variables:**
```env
RESEND_API_KEY=re_xxx
RESEND_FROM_EMAIL=noreply@intimeesolutions.com
RESEND_FROM_NAME=InTime Platform
RESEND_WEBHOOK_SECRET=whsec_xxx
```

---

### 5. JobQueue (6 hours)

**File:** `src/lib/jobs/JobQueue.ts`

**Key Features:**
- PostgreSQL-based queue (no Redis needed)
- Atomic dequeue with SKIP LOCKED
- Job processors for document generation, emails
- Vercel Cron integration
- Retry logic with exponential backoff

**Implementation:**
```typescript
export class JobQueue {
  async addJob(params: {
    jobType: string;
    payload: Record<string, any>;
    userId: string;
    orgId: string;
    priority?: number;
  }): Promise<{ jobId: string }> {
    // Insert into background_jobs table
  }

  async processJobs(maxJobs: number = 10): Promise<void> {
    // 1. Dequeue up to maxJobs using dequeue_next_job()
    // 2. For each job, call appropriate processor
    // 3. Mark as completed or failed
    // 4. Retry failed jobs if attempts < max_attempts
  }

  async getJobStatus(jobId: string): Promise<JobStatus> {
    // Query background_jobs table
  }

  async retryJob(jobId: string): Promise<void> {
    // Reset status to 'pending', increment attempts
  }
}
```

**Job Processors:**
- `src/lib/jobs/processors/generate-document.ts`
- `src/lib/jobs/processors/send-bulk-email.ts`

**Vercel Cron Job:** `src/app/api/cron/process-jobs/route.ts`
```typescript
export async function GET(request: Request) {
  // Verify cron secret
  // Process up to 10 jobs
  // Return stats
}
```

**vercel.json:**
```json
{
  "crons": [
    {
      "path": "/api/cron/process-jobs",
      "schedule": "* * * * *"
    }
  ]
}
```

---

## Phase 2: tRPC Routers (12 hours)

### Router Structure

```
src/lib/trpc/routers/
‚îú‚îÄ‚îÄ workflows.ts      (10 procedures)
‚îú‚îÄ‚îÄ documents.ts      (6 procedures)
‚îú‚îÄ‚îÄ files.ts          (7 procedures)
‚îú‚îÄ‚îÄ emails.ts         (5 procedures)
‚îî‚îÄ‚îÄ jobs.ts           (6 procedures)
```

### 1. Workflows Router (3 hours)

**File:** `src/lib/trpc/routers/workflows.ts`

```typescript
import { z } from 'zod';
import { router, protectedProcedure, adminProcedure } from '../trpc';
import { workflowEngine } from '@/lib/workflows/WorkflowEngine';

export const workflowsRouter = router({
  // List workflow instances
  list: protectedProcedure
    .input(
      z.object({
        workflowId: z.string().optional(),
        entityType: z.string().optional(),
        status: z.enum(['active', 'completed', 'cancelled', 'failed']).optional(),
        limit: z.number().min(1).max(100).default(50),
        offset: z.number().min(0).default(0),
      })
    )
    .query(async ({ input }) => {
      return workflowEngine.listInstances(input);
    }),

  // List workflow definitions
  listDefinitions: protectedProcedure.query(async ({ ctx }) => {
    return ctx.supabase.from('workflows').select('*').eq('is_active', true);
  }),

  // Start new workflow
  startWorkflow: protectedProcedure
    .input(
      z.object({
        workflowId: z.string().uuid(),
        entityType: z.string(),
        entityId: z.string().uuid(),
      })
    )
    .mutation(async ({ input, ctx }) => {
      const instanceId = await workflowEngine.startWorkflow({
        ...input,
        userId: ctx.session.user.id,
        orgId: ctx.session.user.org_id,
      });
      return { instanceId };
    }),

  // Transition workflow
  transition: protectedProcedure
    .input(
      z.object({
        instanceId: z.string().uuid(),
        action: z.string(),
        notes: z.string().optional(),
        expectedVersion: z.number().optional(),
      })
    )
    .mutation(async ({ input, ctx }) => {
      await workflowEngine.transition({
        ...input,
        userId: ctx.session.user.id,
      });
    }),

  // Get available actions
  getAvailableActions: protectedProcedure
    .input(z.object({ instanceId: z.string().uuid() }))
    .query(async ({ input, ctx }) => {
      return workflowEngine.getAvailableActions(
        input.instanceId,
        ctx.session.user.id
      );
    }),

  // Get instance details
  getInstance: protectedProcedure
    .input(z.object({ instanceId: z.string().uuid() }))
    .query(async ({ input }) => {
      return workflowEngine.getInstance(input.instanceId);
    }),

  // Get instance history
  getHistory: protectedProcedure
    .input(z.object({ instanceId: z.string().uuid() }))
    .query(async ({ input }) => {
      return workflowEngine.getHistory(input.instanceId);
    }),

  // Cancel workflow
  cancel: protectedProcedure
    .input(
      z.object({
        instanceId: z.string().uuid(),
        reason: z.string().min(1),
      })
    )
    .mutation(async ({ input, ctx }) => {
      await workflowEngine.cancel(
        input.instanceId,
        ctx.session.user.id,
        input.reason
      );
    }),

  // Get workflow metrics (admin only)
  getMetrics: adminProcedure.query(async () => {
    return workflowEngine.getMetrics();
  }),
});
```

### 2-5. Remaining Routers

Follow same pattern for:
- `documents.ts` (6 procedures)
- `files.ts` (7 procedures)
- `emails.ts` (5 procedures)
- `jobs.ts` (6 procedures)

### Update Root Router

**File:** `src/lib/trpc/root.ts`

```typescript
export const appRouter = router({
  users: usersRouter,
  admin: adminRouter,
  workflows: workflowsRouter,     // NEW
  documents: documentsRouter,     // NEW
  files: filesRouter,             // NEW
  emails: emailsRouter,           // NEW
  jobs: jobsRouter,               // NEW
});
```

---

## Phase 3: Admin UI (8 hours)

### 1. Workflow Dashboard (5 hours)

**File:** `src/app/admin/workflows/page.tsx`

**Features:**
- List all workflow instances with filtering
- Real-time status updates
- Instance detail modal
- State transition history timeline
- Available actions with permission-aware buttons

**Components to Create:**
- `src/components/workflows/InstancesList.tsx`
- `src/components/workflows/InstanceDetailModal.tsx`
- `src/components/workflows/StateTimeline.tsx`
- `src/components/workflows/AvailableActions.tsx`
- `src/components/workflows/WorkflowMetrics.tsx`

### 2. Background Jobs Dashboard (3 hours)

**File:** `src/app/admin/jobs/page.tsx`

**Features:**
- Job queue monitoring
- Job status (pending, processing, completed, failed)
- Retry failed jobs
- View error messages
- Queue statistics

**Components:**
- `src/components/jobs/JobsList.tsx`
- `src/components/jobs/JobDetailModal.tsx`
- `src/components/jobs/JobStats.tsx`

---

## Phase 4: Configuration & Integration (6 hours)

### 1. Supabase Storage Buckets

**Create buckets via Supabase Dashboard:**

```sql
-- Run in SQL Editor
INSERT INTO storage.buckets (id, name, public, file_size_limit, allowed_mime_types)
VALUES
  ('avatars', 'avatars', true, 5242880, '{"image/*"}'),
  ('resumes', 'resumes', false, 10485760, '{"application/pdf", "application/msword", "application/vnd.openxmlformats-officedocument.wordprocessingml.document"}'),
  ('documents', 'documents', false, 52428800, '{"application/pdf", "application/vnd.openxmlformats-officedocument.wordprocessingml.document"}'),
  ('attachments', 'attachments', false, 10485760, NULL),
  ('course-materials', 'course-materials', false, 104857600, NULL);
```

**RLS Policies for Storage:**
```sql
-- Example for 'documents' bucket
CREATE POLICY "Users can upload to documents in their org"
ON storage.objects FOR INSERT
WITH CHECK (
  bucket_id = 'documents' AND
  (storage.foldername(name))[1] = auth_user_org_id()::text
);

CREATE POLICY "Users can download documents from their org"
ON storage.objects FOR SELECT
USING (
  bucket_id = 'documents' AND
  (storage.foldername(name))[1] = auth_user_org_id()::text
);
```

### 2. Event Handlers

**File:** `src/lib/events/handlers/workflow-handlers.ts`

```typescript
import { eventBus } from '@/lib/events/EventBus';
import { documentService } from '@/lib/documents/DocumentService';
import { emailService } from '@/lib/emails/EmailService';
import { jobQueue } from '@/lib/jobs/JobQueue';

// Student graduates ‚Üí Generate certificate
eventBus.subscribe('workflow.state_changed', async (event) => {
  if (
    event.payload.workflowName === 'Student Lifecycle' &&
    event.payload.toState === 'graduated'
  ) {
    // Add background job to generate certificate
    await jobQueue.addJob({
      jobType: 'generate_document',
      payload: {
        templateId: '<certificate-template-id>',
        entityType: 'student',
        entityId: event.payload.entityId,
      },
      userId: event.performedBy,
      orgId: event.metadata.orgId,
    });
  }
});

// Document generated ‚Üí Send email
eventBus.subscribe('document.generated', async (event) => {
  await jobQueue.addJob({
    jobType: 'send_email',
    payload: {
      templateId: '<certificate-email-template-id>',
      to: event.payload.recipientEmail,
      variables: {
        documentUrl: event.payload.downloadUrl,
      },
    },
    userId: event.performedBy,
    orgId: event.metadata.orgId,
  });
});
```

---

## Phase 5: Testing (8 hours)

### Test Coverage Requirements

**Target:** 80%+ coverage on critical paths

### Unit Tests
- `src/lib/workflows/__tests__/WorkflowEngine.test.ts`
- `src/lib/documents/__tests__/DocumentService.test.ts`
- `src/lib/files/__tests__/FileUploadService.test.ts`
- `src/lib/emails/__tests__/EmailService.test.ts`
- `src/lib/jobs/__tests__/JobQueue.test.ts`

### Integration Tests
- Workflow transition ‚Üí Event published
- Document generated ‚Üí File in Storage
- Email sent ‚Üí Log created
- Background job ‚Üí Processor executed

### E2E Tests (Playwright)
- Complete student workflow (application ‚Üí graduated)
- Document generation ‚Üí Email with certificate
- File upload ‚Üí Confirm ‚Üí Download

---

## Environment Variables Checklist

Add to `.env.local`:

```env
# Resend Email Service
RESEND_API_KEY=re_xxx
RESEND_FROM_EMAIL=noreply@intimeesolutions.com
RESEND_FROM_NAME=InTime Platform
RESEND_WEBHOOK_SECRET=whsec_xxx

# Supabase Storage
NEXT_PUBLIC_SUPABASE_STORAGE_URL=https://gkwhxmvugnjwwwiufmdy.supabase.co/storage/v1

# Cron Secret (generate random string)
CRON_SECRET=<generate-using-openssl-rand-base64-32>
```

---

## Quality Gates

Before marking Sprint 3 complete, verify:

- [ ] All 6 migrations applied successfully
- [ ] All 5 core services implemented
- [ ] All 5 tRPC routers created (34 procedures total)
- [ ] Admin UI dashboards functional
- [ ] Supabase Storage buckets configured
- [ ] Event handlers registered
- [ ] Vercel Cron job configured
- [ ] `pnpm tsc --noEmit` passes (0 errors)
- [ ] `pnpm test` passes (80%+ coverage)
- [ ] Manual QA testing completed

---

## Known Issues & Limitations

### 1. Migration Application
**Issue:** Automated migration application via psql failed due to DNS resolution
**Workaround:** Apply migrations manually via Supabase SQL Editor
**Resolution:** Working as intended (manual application safer for production)

### 2. Puppeteer in Production
**Issue:** Puppeteer may have memory issues in Vercel serverless functions
**Mitigation:** Run document generation in background jobs with timeout limits
**Alternative:** Consider using Puppeteer in Docker container on separate infrastructure

### 3. Rate Limiting
**Issue:** Resend free tier: 100 emails/day
**Mitigation:** Monitor usage, upgrade plan if needed
**Cost:** Resend Pro: $20/month (50K emails)

---

## Next Steps for QA Agent

Once implementation complete, QA should test:

1. **Workflow Engine:**
   - Start student workflow
   - Transition through all states
   - Verify permission checks prevent unauthorized transitions
   - Test optimistic locking (concurrent transitions)
   - Cancel workflow

2. **Document Generation:**
   - Generate certificate PDF
   - Generate offer letter PDF
   - Verify files uploaded to Supabase Storage
   - Download generated documents
   - Test with missing variables (should fail gracefully)

3. **File Upload:**
   - Upload avatar (should be public)
   - Upload resume (should be private)
   - Verify RLS prevents cross-org access
   - Delete file (should soft-delete)

4. **Email Service:**
   - Send welcome email
   - Send password reset
   - Verify emails received
   - Check email_logs table updated
   - Test webhook handler

5. **Background Jobs:**
   - Create background job
   - Trigger cron job manually
   - Verify job processed
   - Test job retry on failure
   - Check job stats

6. **Security:**
   - Verify RLS policies prevent cross-org data access
   - Test permission-based workflow transitions
   - Verify file upload RLS policies
   - Test service role can bypass RLS for background jobs

---

## Deployment Checklist

Before deploying to production:

1. **Environment Variables:**
   - [ ] RESEND_API_KEY configured
   - [ ] RESEND_WEBHOOK_SECRET configured
   - [ ] CRON_SECRET configured

2. **Database:**
   - [ ] All migrations applied
   - [ ] Seed data verified
   - [ ] RLS policies tested

3. **Storage:**
   - [ ] All buckets created
   - [ ] RLS policies applied
   - [ ] File size limits configured

4. **Vercel:**
   - [ ] Cron job configured in vercel.json
   - [ ] Deployed to production
   - [ ] Cron job tested

5. **Monitoring:**
   - [ ] Sentry configured for error tracking
   - [ ] Email delivery monitoring
   - [ ] Job queue monitoring
   - [ ] Workflow instance monitoring

---

## Files Created So Far

### Database Migrations (6 files)
‚úÖ `src/lib/db/migrations/010_create_workflow_engine.sql` (625 lines)
‚úÖ `src/lib/db/migrations/011_create_document_service.sql` (272 lines)
‚úÖ `src/lib/db/migrations/012_create_file_management.sql` (61 lines)
‚úÖ `src/lib/db/migrations/013_create_email_service.sql` (269 lines)
‚úÖ `src/lib/db/migrations/014_create_background_jobs.sql` (185 lines)
‚úÖ `src/lib/db/migrations/015_seed_workflows.sql` (298 lines)

### Type Definitions (1 file)
‚úÖ `src/lib/workflows/types.ts` (133 lines)

### Scripts (1 file)
‚úÖ `scripts/apply-sprint3-migrations.ts` (171 lines)

### Documentation (1 file)
‚úÖ `SPRINT-3-DEVELOPER-HANDOFF.md` (this file)

---

## Total Scope Remaining

**Estimated Implementation Time:** 40-50 hours

**Files to Create:** ~53 files
- 5 Services (+ 5 type files) = 10 files
- 2 Job Processors = 2 files
- 5 tRPC Routers = 5 files
- 2 Admin UI Pages + 9 Components = 11 files
- 1 Cron API Route = 1 file
- 1 Webhook API Route = 1 file
- Event Handlers = 1 file
- 15 Test Files = 15 files
- 4 Template Files (document) = 4 files
- 4 Template Files (email) = 4 files

**Lines of Code:** ~8,000 LOC (estimated)

---

## Success Metrics

At Sprint 3 completion:

- **Functional:**
  - ‚úÖ Workflow state machines operational
  - ‚úÖ Document generation (PDF/DOCX) working
  - ‚úÖ File upload/download via Supabase Storage
  - ‚úÖ Email delivery via Resend
  - ‚úÖ Background job processing via Vercel Cron

- **Quality:**
  - ‚úÖ 0 TypeScript errors
  - ‚úÖ 80%+ test coverage
  - ‚úÖ All RLS policies tested
  - ‚úÖ No security vulnerabilities

- **Performance:**
  - ‚úÖ Workflow transition < 100ms (p95)
  - ‚úÖ Document generation < 3s
  - ‚úÖ File upload presigned URL < 200ms
  - ‚úÖ Email send < 2s
  - ‚úÖ Background job processing < 60s

---

**Status:** Ready for continued implementation

**Next Action:** Apply migrations 010-015 via Supabase SQL Editor (see instructions above)

**Contact:** Developer Agent (this handoff document)

**Last Updated:** 2025-11-19
